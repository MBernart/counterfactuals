{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "data['species'] = iris.target\n",
    "\n",
    "# Encode the target labels (species)\n",
    "label_encoder = LabelEncoder()\n",
    "data['species'] = label_encoder.fit_transform(data['species'])\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('species', axis=1).values\n",
    "y = data['species'].values\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55b61126",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(IrisNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 16)  # First hidden layer\n",
    "        self.fc2 = nn.Linear(16, 8)          # Second hidden layer\n",
    "        self.fc3 = nn.Linear(8, output_dim)  # Output layer (3 classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x  # No softmax here, as CrossEntropyLoss includes softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cf0de1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 1.0757, Accuracy: 0.3667\n",
      "Epoch [20/1000], Loss: 1.0404, Accuracy: 0.7333\n",
      "Epoch [30/1000], Loss: 1.0046, Accuracy: 0.7917\n",
      "Epoch [40/1000], Loss: 0.9660, Accuracy: 0.7917\n",
      "Epoch [50/1000], Loss: 0.9229, Accuracy: 0.7917\n",
      "Epoch [60/1000], Loss: 0.8747, Accuracy: 0.7917\n",
      "Epoch [70/1000], Loss: 0.8225, Accuracy: 0.8167\n",
      "Epoch [80/1000], Loss: 0.7671, Accuracy: 0.8083\n",
      "Epoch [90/1000], Loss: 0.7110, Accuracy: 0.8083\n",
      "Epoch [100/1000], Loss: 0.6570, Accuracy: 0.8250\n",
      "Epoch [110/1000], Loss: 0.6072, Accuracy: 0.8250\n",
      "Epoch [120/1000], Loss: 0.5622, Accuracy: 0.8250\n",
      "Epoch [130/1000], Loss: 0.5216, Accuracy: 0.8333\n",
      "Epoch [140/1000], Loss: 0.4845, Accuracy: 0.8417\n",
      "Epoch [150/1000], Loss: 0.4504, Accuracy: 0.8417\n",
      "Epoch [160/1000], Loss: 0.4189, Accuracy: 0.8500\n",
      "Epoch [170/1000], Loss: 0.3896, Accuracy: 0.8667\n",
      "Epoch [180/1000], Loss: 0.3623, Accuracy: 0.8833\n",
      "Epoch [190/1000], Loss: 0.3370, Accuracy: 0.9000\n",
      "Epoch [200/1000], Loss: 0.3136, Accuracy: 0.9167\n",
      "Epoch [210/1000], Loss: 0.2916, Accuracy: 0.9250\n",
      "Epoch [220/1000], Loss: 0.2702, Accuracy: 0.9333\n",
      "Epoch [230/1000], Loss: 0.2499, Accuracy: 0.9417\n",
      "Epoch [240/1000], Loss: 0.2309, Accuracy: 0.9333\n",
      "Epoch [250/1000], Loss: 0.2133, Accuracy: 0.9500\n",
      "Epoch [260/1000], Loss: 0.1970, Accuracy: 0.9500\n",
      "Epoch [270/1000], Loss: 0.1820, Accuracy: 0.9500\n",
      "Epoch [280/1000], Loss: 0.1683, Accuracy: 0.9500\n",
      "Epoch [290/1000], Loss: 0.1559, Accuracy: 0.9583\n",
      "Epoch [300/1000], Loss: 0.1449, Accuracy: 0.9583\n",
      "Epoch [310/1000], Loss: 0.1351, Accuracy: 0.9583\n",
      "Epoch [320/1000], Loss: 0.1265, Accuracy: 0.9667\n",
      "Epoch [330/1000], Loss: 0.1189, Accuracy: 0.9667\n",
      "Epoch [340/1000], Loss: 0.1121, Accuracy: 0.9667\n",
      "Epoch [350/1000], Loss: 0.1062, Accuracy: 0.9667\n",
      "Epoch [360/1000], Loss: 0.1008, Accuracy: 0.9667\n",
      "Epoch [370/1000], Loss: 0.0961, Accuracy: 0.9667\n",
      "Epoch [380/1000], Loss: 0.0919, Accuracy: 0.9667\n",
      "Epoch [390/1000], Loss: 0.0882, Accuracy: 0.9750\n",
      "Epoch [400/1000], Loss: 0.0848, Accuracy: 0.9750\n",
      "Epoch [410/1000], Loss: 0.0819, Accuracy: 0.9750\n",
      "Epoch [420/1000], Loss: 0.0793, Accuracy: 0.9750\n",
      "Epoch [430/1000], Loss: 0.0769, Accuracy: 0.9750\n",
      "Epoch [440/1000], Loss: 0.0748, Accuracy: 0.9833\n",
      "Epoch [450/1000], Loss: 0.0728, Accuracy: 0.9833\n",
      "Epoch [460/1000], Loss: 0.0711, Accuracy: 0.9833\n",
      "Epoch [470/1000], Loss: 0.0694, Accuracy: 0.9833\n",
      "Epoch [480/1000], Loss: 0.0680, Accuracy: 0.9833\n",
      "Epoch [490/1000], Loss: 0.0666, Accuracy: 0.9833\n",
      "Epoch [500/1000], Loss: 0.0654, Accuracy: 0.9833\n",
      "Epoch [510/1000], Loss: 0.0643, Accuracy: 0.9833\n",
      "Epoch [520/1000], Loss: 0.0633, Accuracy: 0.9833\n",
      "Epoch [530/1000], Loss: 0.0623, Accuracy: 0.9833\n",
      "Epoch [540/1000], Loss: 0.0614, Accuracy: 0.9833\n",
      "Epoch [550/1000], Loss: 0.0606, Accuracy: 0.9833\n",
      "Epoch [560/1000], Loss: 0.0598, Accuracy: 0.9833\n",
      "Epoch [570/1000], Loss: 0.0591, Accuracy: 0.9833\n",
      "Epoch [580/1000], Loss: 0.0584, Accuracy: 0.9833\n",
      "Epoch [590/1000], Loss: 0.0578, Accuracy: 0.9833\n",
      "Epoch [600/1000], Loss: 0.0572, Accuracy: 0.9833\n",
      "Epoch [610/1000], Loss: 0.0566, Accuracy: 0.9833\n",
      "Epoch [620/1000], Loss: 0.0561, Accuracy: 0.9833\n",
      "Epoch [630/1000], Loss: 0.0556, Accuracy: 0.9833\n",
      "Epoch [640/1000], Loss: 0.0552, Accuracy: 0.9833\n",
      "Epoch [650/1000], Loss: 0.0547, Accuracy: 0.9833\n",
      "Epoch [660/1000], Loss: 0.0543, Accuracy: 0.9833\n",
      "Epoch [670/1000], Loss: 0.0539, Accuracy: 0.9833\n",
      "Epoch [680/1000], Loss: 0.0535, Accuracy: 0.9833\n",
      "Epoch [690/1000], Loss: 0.0532, Accuracy: 0.9833\n",
      "Epoch [700/1000], Loss: 0.0528, Accuracy: 0.9833\n",
      "Epoch [710/1000], Loss: 0.0525, Accuracy: 0.9833\n",
      "Epoch [720/1000], Loss: 0.0522, Accuracy: 0.9833\n",
      "Epoch [730/1000], Loss: 0.0519, Accuracy: 0.9833\n",
      "Epoch [740/1000], Loss: 0.0516, Accuracy: 0.9833\n",
      "Epoch [750/1000], Loss: 0.0514, Accuracy: 0.9833\n",
      "Epoch [760/1000], Loss: 0.0511, Accuracy: 0.9833\n",
      "Epoch [770/1000], Loss: 0.0509, Accuracy: 0.9833\n",
      "Epoch [780/1000], Loss: 0.0506, Accuracy: 0.9833\n",
      "Epoch [790/1000], Loss: 0.0504, Accuracy: 0.9833\n",
      "Epoch [800/1000], Loss: 0.0502, Accuracy: 0.9833\n",
      "Epoch [810/1000], Loss: 0.0500, Accuracy: 0.9833\n",
      "Epoch [820/1000], Loss: 0.0498, Accuracy: 0.9833\n",
      "Epoch [830/1000], Loss: 0.0496, Accuracy: 0.9833\n",
      "Epoch [840/1000], Loss: 0.0494, Accuracy: 0.9833\n",
      "Epoch [850/1000], Loss: 0.0492, Accuracy: 0.9833\n",
      "Epoch [860/1000], Loss: 0.0490, Accuracy: 0.9833\n",
      "Epoch [870/1000], Loss: 0.0488, Accuracy: 0.9833\n",
      "Epoch [880/1000], Loss: 0.0487, Accuracy: 0.9833\n",
      "Epoch [890/1000], Loss: 0.0485, Accuracy: 0.9833\n",
      "Epoch [900/1000], Loss: 0.0484, Accuracy: 0.9833\n",
      "Epoch [910/1000], Loss: 0.0482, Accuracy: 0.9833\n",
      "Epoch [920/1000], Loss: 0.0481, Accuracy: 0.9833\n",
      "Epoch [930/1000], Loss: 0.0479, Accuracy: 0.9833\n",
      "Epoch [940/1000], Loss: 0.0478, Accuracy: 0.9833\n",
      "Epoch [950/1000], Loss: 0.0476, Accuracy: 0.9833\n",
      "Epoch [960/1000], Loss: 0.0475, Accuracy: 0.9833\n",
      "Epoch [970/1000], Loss: 0.0474, Accuracy: 0.9833\n",
      "Epoch [980/1000], Loss: 0.0473, Accuracy: 0.9833\n",
      "Epoch [990/1000], Loss: 0.0471, Accuracy: 0.9833\n",
      "Epoch [1000/1000], Loss: 0.0470, Accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = IrisNet(X_train.shape[1], len(set(y)))  # 4 features, 3 classes\n",
    "\n",
    "# Set up loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # CrossEntropyLoss includes softmax\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    optimizer.zero_grad()  # Clear gradients\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    _, predicted_labels = torch.max(outputs, 1)\n",
    "    correct = (predicted_labels == y_train_tensor).sum().item()\n",
    "    train_accuracy = correct / y_train_tensor.size(0)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:  # Print every 10 epochs\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {train_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "badcc275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient calculation during inference\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    _, predicted_labels = torch.max(test_outputs, 1)\n",
    "    correct = (predicted_labels == y_test_tensor).sum().item()\n",
    "    test_accuracy = correct / y_test_tensor.size(0)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70fd24dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "# torch.save(model.state_dict(), 'iris_model.pth')\n",
    "scripted_model = torch.jit.script(model)  # or torch.jit.trace(model, example_input)\n",
    "scripted_model.save(\"temp_model.pt\")\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f47b5b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.7720,  7.4369, -2.9274], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row = data.iloc[0, :-1].values\n",
    "\n",
    "model(torch.tensor(first_row, dtype=torch.float32))\n",
    "# Load the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcfcd094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.1, 3.5, 1.4, 0.2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
