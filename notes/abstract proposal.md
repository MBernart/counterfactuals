The critical need for explainability (XAI) in complex black-box models has driven interest in Counterfactual Explanations (CFEs). However, the proliferation of CFE methods presents challenges in standardization, comparison, and synthesis. This paper introduces a scalable framework to address these issues. Our framework orchestrates diverse counterfactual explainers by dockerizing them as distributed workers. This architecture enables both standardized CFE generation and the creation of powerful CFE ensembles. We integrate various aggregation strategies for these ensembles, including Pareto front optimization, Ideal Point, Balanced Point, and density-based (k-NN) methods. To validate our framework and assess the practical utility of these techniques, we conduct a comprehensive user study. This study captures user preferences between counterfactuals generated by different methods, ensembles, and aggregators. Our results provide a human-centric comparative analysis, offering valuable insights for evaluating CFE quality and fostering a deeper understanding of the underlying models.
