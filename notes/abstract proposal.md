The critical need for explainability (XAI) in complex black-box models continues to drive interest in Counterfactual Explanations (CFEs). However, the proliferation of CFE methods presents challenges in standardization, comparison, and synthesis. This paper proposes a scalable framework to address these issues.

Our framework will orchestrate diverse counterfactual explainers by dockerizing them as distributed workers. This architecture will enable both standardized CFE generation and the creation of powerful CFE ensembles. We will integrate various selection strategies for picking CFEs, including Pareto front, Ideal Point, Balanced Point, and density-based (k-NN) methods, etc.

To validate our framework and assess the practical utility of these techniques, we will conduct a comprehensive user study. This study will capture user preferences between counterfactuals generated by different methods, ensembles, and selectors. Our results will provide a human-centric comparative analysis, offering valuable insights for evaluating CFE quality and fostering a deeper understanding of the underlying models.
